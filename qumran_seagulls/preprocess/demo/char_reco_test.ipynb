{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qumran_seagulls.types import *\n",
    "from qumran_seagulls.utils import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/lines_cropped/P123-Fg001-R-C01-R01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['line_8.jpg',\n",
       " 'line_7.jpg',\n",
       " 'line_2.jpg',\n",
       " 'line_5.jpg',\n",
       " 'line_9.jpg',\n",
       " 'line_11.jpg',\n",
       " 'line_6.jpg',\n",
       " 'data.csv',\n",
       " 'line_1.jpg',\n",
       " 'line_10.jpg',\n",
       " 'line_3.jpg',\n",
       " 'line_12.jpg',\n",
       " 'line_4.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(214, 1870),\n",
       " (236, 2014),\n",
       " (171, 1644),\n",
       " (196, 2324),\n",
       " (213, 1754),\n",
       " (164, 1518),\n",
       " (208, 2156),\n",
       " (253, 659),\n",
       " (236, 1582),\n",
       " (219, 2415),\n",
       " (184, 1406),\n",
       " (197, 2027)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [cv2.imread(os.path.join(path, f), 0) for f in os.listdir(path) if f.endswith('jpg')]\n",
    "len(lines)\n",
    "[l.shape for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(lines[1])\n",
    "lines = [remove_blobs(thresh_invert(line), 10) for line in lines]\n",
    "show(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def histogram_cleaning(line: array, width_thresh: int = 15, span_thresh: int = 30) -> List[array]:\n",
    "    histogram = np.where(line > 0, 1, 0).sum(axis=0)\n",
    "    zeros = np.where(histogram==0)[0]\n",
    "    change_idces = np.where(np.diff(zeros) > 1)[0]\n",
    "    starts = [zeros[i] for i in change_idces] \n",
    "    ends = [zeros[i+1] for i in change_idces]\n",
    "\n",
    "    # remove very narrow zero areas as they might be of the same character\n",
    "    widths = [e - s for s, e in zip(starts, ends)]\n",
    "    remove = [i for i, w in enumerate(widths) if w < width_thresh]\n",
    "    ends = [e for i, e in enumerate(ends) if i not in remove]\n",
    "    starts = [s for i, s in enumerate(starts) if i not in [j+1 for j in remove]]\n",
    "\n",
    "    # remove very narrow spans for the same reason\n",
    "    spans = [starts[i+1] - e for i, e in enumerate(ends[:-1])]\n",
    "    remove = [i for i, s in enumerate(spans) if s < span_thresh]\n",
    "    ends = [e for i, e in enumerate(ends) if i not in remove]\n",
    "    starts = [s for i, s in enumerate(starts) if i not in [j+1 for j in remove]]\n",
    "    #visualize(line, histogram, starts, ends)\n",
    "\n",
    "    return [line[:, s:e+16] for s, e in zip(starts, ends)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with a line\n",
    "line = lines[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(image: array, win_width: int = 50, win_step: int = 10) -> List[array]:\n",
    "    num_windows = ceil((image.shape[1] - win_width) / win_step)\n",
    "    windows = [image[:, i*win_step : win_width + i*win_step] for i in range(num_windows)]\n",
    "    return [w for w in windows if w.min() == 0]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qumran_seagulls.preprocess.char_segm.char_segm import histogram_cleaning\n",
    "\n",
    "crops = histogram_cleaning(line)\n",
    "all_windows = [create_windows(w) for w in crops]\n",
    "crops = [cs for i, cs in enumerate(crops) if len(all_windows[i]) > 0]\n",
    "all_windows = [ws for ws in all_windows if len(ws) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crops), len(all_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qumran_seagulls.models.cnn import default_cnn_monkbrill\n",
    "model = default_cnn_monkbrill().eval()\n",
    "model.load_pretrained('checkpoints/cnn_labels_augm_fuzzy.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = [model.predict_scores(wins) for wins in all_windows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_likelihoods(crop: array, scores: Tensor) -> Tensor:\n",
    "        # heuristic\n",
    "        num_chars = crop.shape[1] // 64 + 1\n",
    "        max_probs = [score.softmax(-1).max() for score in scores]\n",
    "        minima = find_peaks(-array(max_probs), prominence=0.01)[0]\n",
    "        \n",
    "        minima = [m for m in minima if m not in [1, len(max_probs)-2]]\n",
    "        if len(minima) > num_chars-1:\n",
    "            values = [max_probs[i] for i in minima]\n",
    "            minima = [minima[i] for i, p  in enumerate(values) if p in sorted(values)[:num_chars-1]]\n",
    "        \n",
    "        if num_chars == 1 or not len(minima):\n",
    "            lkhds = [scores.mean(0).softmax(-1)]\n",
    "\n",
    "        else:\n",
    "            # average over sliding windows for each char range\n",
    "            lkhds = [scores[:minima[0]].mean(0)]\n",
    "            lkhds.extend([scores[m+1: minima[i+1]].mean(0) for i, m in enumerate(minima[:-1])])\n",
    "            lkhds.append(scores[minima[-1] + 1:].mean(0))\n",
    "            lkhds = [l.softmax(-1) for l in lkhds if not torch.isnan(l[0])]\n",
    "\n",
    "        return torch.stack(lkhds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-f29f7c64cddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_peaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ind = 11\n",
    "crop, scores = crops[ind], all_scores[ind]\n",
    "from scipy.signal import find_peaks\n",
    "show(crop)\n",
    "\n",
    "num_chars = crop.shape[1] // 64 + 1\n",
    "max_probs = [score.softmax(-1).max().item() for score in scores]\n",
    "minima = find_peaks(-np.array(max_probs), prominence=0.01)[0]\n",
    "maxima = find_peaks(np.array(max_probs))[0]\n",
    "print(crop.shape, num_chars)\n",
    "\n",
    "print('num windows', len(max_probs))\n",
    "print('num minima before', len(minima), minima)\n",
    "minima = [m for m in minima if m not in [1, len(max_probs)-2]]\n",
    "if len(minima) > num_chars-1:\n",
    "    values = [max_probs[i] for i in minima]\n",
    "    minima = [minima[i] for i, p  in enumerate(values) if p in sorted(values)[:num_chars-1]]\n",
    "    \n",
    "print(minima)\n",
    "print(max_probs)\n",
    "plt.plot(max_probs)\n",
    "plt.vlines(minima, 0, 1, color=\"C1\")\n",
    "plt.vlines(maxima, 0, 1, color=\"C3\", linestyles='dotted')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "Ls = get_likelihoods(crop, scores)\n",
    "print(Ls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 24, 2]\n",
      "['Dalet', 'Resh', 'Tsadi-final', 'Het', 'Het', 'Waw', 'Zayin', 'Lamed', 'Tet', 'Bet', 'Bet', 'Bet']\n",
      "['Dalet', 'Waw', 'Bet']\n"
     ]
    }
   ],
   "source": [
    "path, qs, Qfinal = Viterbi(torch.flip(Ls, [0]))\n",
    "print(path)\n",
    "print([LABEL_MAP[s.argmax(-1).item()] for s in scores])\n",
    "print([LABEL_MAP[i] for i in path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qumran_seagulls.models.viterbi import default_viterbi\n",
    "Viterbi = default_viterbi('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Viterbi(object):\n",
    "    def __init__(self, \n",
    "                 num_classes: int, \n",
    "                 transition_matrix: Tensor,\n",
    "                 T_sos: Tensor,\n",
    "                 T_eos: Tensor):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.transition = transition_matrix      # K x K\n",
    "        self.T_sos = T_sos \n",
    "        self.T_eos = T_eos        \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, likelihoods: Tensor) -> Tuple[List[int], Tensor, float]:\n",
    "        T = len(likelihoods) # sequence length\n",
    "\n",
    "        if T == 1:\n",
    "            # return only from input transition\n",
    "            _q = likelihoods[0, :] * self.T_sos\n",
    "            return [_q.argmax().item()], _q, _q.max().item()\n",
    "\n",
    "        K = self.num_classes\n",
    "\n",
    "        qs = torch.empty((T, K), device=likelihoods.device)         \n",
    "        paths = torch.empty((T-1, K), dtype=int, device=qs.device)\n",
    "        qs[0, :] = likelihoods[0, :] * self.T_sos \n",
    "        for step in range(1, T):\n",
    "            # @todo: find the broadcasting magic\n",
    "            for j in range(K):\n",
    "                query = (qs[step-1,:] * self.transition.T[j] * likelihoods[step, j])\n",
    "                paths[step-1, j] = query.argmax()\n",
    "                qs[step, j] = query.max()\n",
    "        last_path = (qs[step, :] * self.T_eos).argmax().item()\n",
    "        qs_end = (qs[step, :] * self.T_eos).max().item()\n",
    "\n",
    "        best_path = [last_path]\n",
    "        for step in range(T-1):\n",
    "            last_path = paths[-1 - step, last_path].item()\n",
    "            best_path.append(last_path)\n",
    "            \n",
    "        return best_path[::-1], qs, qs_end\n",
    "\n",
    "\n",
    "def default_viterbi(device: str):\n",
    "    # remove transition probs from corresponding medial and final characters\n",
    "    T_sos = torch.tensor([1/23 if i not in [8, 12, 15, 22] else 0 for i in range(27)], device=device)\n",
    "    T_eos = torch.tensor([1/24 if i not in [11, 13, 23] else 0 for i in range(27)], device=device)\n",
    "    \n",
    "    return Viterbi(num_classes=27, transition_matrix=torch.load('checkpoints/trans.p'), T_sos = T_sos, T_eos = T_eos)\n",
    "\n",
    "Viterbi = default_viterbi('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alef', 'Alef', 'Alef', 'Kaf-final', 'Resh']\n"
     ]
    }
   ],
   "source": [
    "path, qs, Qfinal = Viterbi(torch.flip(Ls, [0]))\n",
    "\n",
    "print([LABEL_MAP[i] for i in path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "num_chars = crop.shape[1] // 64 + 1\n",
    "max_probs = [score.softmax(-1).max().item() for score in scores]\n",
    "minima = find_peaks(-np.array(max_probs), prominence=0.01)[0]\n",
    "maxima = find_peaks(np.array(max_probs))[0]\n",
    "minima = [m for m in minima if m not in [1, len(max_probs)-2]]\n",
    "if len(minima) > num_chars-1:\n",
    "    values = [max_probs[i] for i in minima]\n",
    "    minima = [minima[i] for i, p  in enumerate(values) if p in sorted(values)[:num_chars-1]]\n",
    "    \n",
    "lhds = [scores[:minima[0]].mean(0)]\n",
    "lhds += [scores[m+1: minima[i+1]].mean(0) for i, m in enumerate(minima[:-1])]\n",
    "lhds.append(scores[minima[-1] + 1:].mean(0))\n",
    "print(len(lhds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
